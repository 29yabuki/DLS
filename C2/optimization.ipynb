{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0dcead-745e-4ec0-9b6c-a98ddb9d5ccf",
   "metadata": {},
   "source": [
    "# Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e549e-e415-4628-9bc0-414c2b2ccb7d",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b7fcb-b333-458a-b5ea-3e5d9e84dcd0",
   "metadata": {},
   "source": [
    "| Type                        | Mini-batch size    | \n",
    "|-----------------------------|--------------------|\n",
    "| Batch gradient descent      | $m_t = m$           |\n",
    "| Stochastic gradient descent | $m_t = 1$           |\n",
    "| Mini-batch gradient descent | $m_t \\in (1, m)$     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964f5e1c-fecc-42a8-8d6a-e6f2a10cee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_gd(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 # num of layers\n",
    "\n",
    "    # update rule\n",
    "    for l in range(1, L + 1):\n",
    "        W = parameters[\"W\" + str(l)]\n",
    "        dW = grads[\"dW\" + str(l)]\n",
    "        b = parameters[\"b\" + str(l)]\n",
    "        db = grads[\"db\" + str(l)]\n",
    "        parameters[\"W\" + str(l)] = W - learning_rate * dW\n",
    "        parameters[\"b\" + str(l)] = b - learning_rate * db\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36219cf-a419-4146-9622-703222f3fba2",
   "metadata": {},
   "source": [
    "### Batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e9768cf-1672-45ef-96d5-27e7bd6310fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X, Y, layers_dims, num_iterations, learning_rate):\n",
    "    m = X.shape[1]  # num of train examples\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        a, caches = forward_propagation(X, parameters)\n",
    "        cost_total = compute_cost(a, Y)\n",
    "        grads = backward_propagation(a, caches, parameters)\n",
    "        parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "        cost_avg = cost_total / m\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e8bc8-9a78-40ac-b390-d1c3b0844351",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2807f1c8-dc6e-46ca-8b73-f33fdd2a6dc3",
   "metadata": {},
   "source": [
    "Implementing SGD needs 3 loops:\n",
    "1. Over the number of iterations\n",
    "2. Over the $m$ training examples\n",
    "3. Over the layers—to update all parameters, from $(W^{[1]},b^{[1]})$ to $(W^{[L]},b^{[L]})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e87f606-e8c4-456b-bf6a-11ddf3c1a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, Y, layers_dims, num_iterations, learning_rate):\n",
    "    m = X.shape[1]  # num of train examples\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        cost_total = 0\n",
    "        for j in range(m):\n",
    "            a, caches = forward_propagation(X[:, j:j+1], parameters)\n",
    "            cost_total += compute_cost(a, Y[:, j:j+1])\n",
    "            grads = backward_propagation(a, caches, parameters)\n",
    "            parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "        cost_avg = cost_total / m\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f672d-6869-4fc9-8f96-9de05eda4787",
   "metadata": {},
   "source": [
    "### Mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b1c02-9d06-4369-82ec-e10cd267a267",
   "metadata": {},
   "source": [
    "In mini-batch gradient descent there are multiple gradient steps—once per mini-batch. \n",
    "\n",
    "If there's 5000 mini-batches, there's 5000 updates per epoch.\n",
    "\n",
    "If train set is small $(m \\le 2000)$: use batch GD. Otherwise choose a mini-batch size.\n",
    "\n",
    "Use powers of 2 for typical mini-batch sizes: $64, 128, 256, 512, 1024, \\ldots$ due to hardware memory alignment.\n",
    "\n",
    "There are two steps in building mini-batches: shuffling and partioning.\n",
    "\n",
    "1. Shuffling\n",
    "\t- Create a shuffled version of the train set $(X, Y)$.\n",
    "\t- Each column of $X$ an $Y$ corresponds to a single train example.\n",
    "\t- Shuffle synchronously—the $i^\\text{th}$ column $X$ stays paired with the $i^\\text{th}$ column of $Y$ after shuffling.\n",
    "\t- Shuffling ensures that examples are split randomly into different mini-batches.\n",
    "2. Partitioning\n",
    "\t- Divide the shuffled train set into mini-batches of size $m_t$.\n",
    "\t- If the num of train examples is not divisible by $m_t$, the final mini-batch will have fewer examples. This is normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a23f21-0cb5-4056-a445-79185835c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \n",
    "    m = X.shape[1] # num of train examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # shuffling\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1, m))\n",
    "    \n",
    "    # partition\n",
    "    num_complete_minibatches = math.floor(m / mini_batch_size) # num of mini batches\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        start = k * mini_batch_size\n",
    "        end = (k+1) * mini_batch_size\n",
    "        mini_batch_X = shuffled_X[:, start:end]\n",
    "        mini_batch_Y = shuffled_Y[:, start:end]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # end case when m is not divisisible by m_t\n",
    "    if m % mini_batch_size != 0:\n",
    "        rem_start = num_complete_minibatches * mini_batch_size\n",
    "        rem_end = m\n",
    "        mini_batch_X = shuffled_X[:, rem_start:rem_end]\n",
    "        mini_batch_Y = shuffled_Y[:, rem_start:rem_end]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eec9df-273d-432a-9d68-33aaf3317888",
   "metadata": {},
   "source": [
    "Mini-batch gradient descent procedure:\n",
    "1. Forward propagation on $X^{t}$\n",
    "\t1. $Z^{[1]} = W^{[1]} X^{\\{t\\}} + b^{[1]}$\n",
    "\t2. $A^{[1]} = g^{[1]}(Z^{[1]})$\n",
    "\t3. $\\ldots$\n",
    "\t4. $Z^{[1]} = W^{[1]} A^{[L-1]} + b^{[L]}$\n",
    "\t5. $A^{[L]} = g^{[L]}(Z^{[L]})$\n",
    "2. Compute cost for mini-batch $\\displaystyle J^{\\{t\\}} = \\frac{1}{m_t} \\sum_{i=1}^{1000} \\mathcal{L}(\\hat y^{(i)}, y^{(i)}) + \\frac{\\lambda}{2m} + \\sum_{l} \\vert \\vert W^{[l]} \\vert \\vert_{F}^2$\n",
    "3. Backward propagation by computing gradients w.r.t. $J^{\\{t\\}}$ using ($X^{\\{t\\}}, Y^{\\{t\\}})$\n",
    "\t1. $dZ^{[L]} = A^{[L]} - Y^{\\{t\\}}$\n",
    "\t2. $dW^{[L]} = \\frac{1}{m_t} dZ^{[L]}(A^{[L-1]})^\\intercal + \\frac{\\lambda}{m} W^{[L]}$\n",
    "\t3. $db^{[L]} = \\frac{1}{m_t} \\sum dZ^{[L]}$\n",
    "\t4. $\\ldots$\n",
    "\t5. $dA^{[1]} = (W^{[2]})^\\intercal \\cdot dZ^{[2]}$\n",
    "\t6. $dZ^{[1]} = dA^{[1]} \\ast g^{[1]'}(Z^{[1]})$\n",
    "\t7.  $dW^{[1]} = \\frac{1}{m_t} dZ^{[1]} \\cdot X^\\intercal + \\frac{\\lambda}{m} W^{[1]}$\n",
    "\t8. $db^{[1]} = \\frac{1}{m_t} \\sum dZ^{[1]}$\n",
    "4. Update the parameters\n",
    "\t1. $W^{[l]} := W^{[l]} - \\alpha \\cdot dW^{[l]}$\n",
    "\t2. $b^{[l]} := b^{[l]} - \\alpha \\cdot db^{[l]}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832ac325-3dda-47e7-ae55-1773f7b202e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_descent(X, Y, layers_dims, num_epochs, mini_batch_size, learning_rate):\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # create shuffled mini-batches\n",
    "        mini_batches = random_mini_batches(X, Y, mini_batch_size)\n",
    "\n",
    "        # loop over each mini-batch\n",
    "        for mini_batch in mini_batches:\n",
    "            (mini_batch_X, mini_batch_Y) = mini_batch\n",
    "\n",
    "            a, caches = forward_propagation(mini_batch_X, parameters)\n",
    "            cost_total = compute_cost(a, mini_batch_Y)\n",
    "            grads = backward_propagation(a, caches, parameters)\n",
    "            parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "\n",
    "        print(f'Epoch {epoch}: Cost = {cost_total / mini_batch_size}')\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4a1a0-ca76-4bc3-ab62-1425bb280239",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b1b6a-d0c8-4f7a-8d5e-218f35c1bbb3",
   "metadata": {},
   "source": [
    "Problem with standard gradient descent:\n",
    "1. When optimizing $J$ with elongated contours, the algorithm may oscillate back and forth across the narrow dimension (e.g., vertical axis).\n",
    "2. This forces the use of a small learning rate $\\alpha$, since a large $\\alpha$ might cause overshooting and end up diverging.\n",
    "3. Convergence slows due to small $\\alpha$.\n",
    "\n",
    "What do we want?\n",
    "- Slow learning in the vertical direction to prevent oscillations.\n",
    "- Fast learning in the horizontal direction to quickly reach the minimum.\n",
    "\n",
    "The solution? Use momentum.\n",
    "- Momentum smooths the optimization path by averaging gradients over time.\n",
    "- Averaging causes vertical oscillations to cancel out.\n",
    "- Averaging causes horizontal direction to accumulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28fe103e-03af-4780-9cab-988ca01ec0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters):\n",
    "    L = len(parameters) // 2 # num of layers\n",
    "    v = {}\n",
    "    \n",
    "    for l in range(1, L + 1):\n",
    "        v[\"dW\" + str(l)] = np.zeros(parameters[\"W\" + str(l)].shape)\n",
    "        v[\"db\" + str(l)] = np.zeros(parameters[\"b\" + str(l)].shape)\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7cbfa70-b51a-4ca0-8262-67a7335b6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    parameters: dict containing your params:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads: dict containing your grads for each params:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    v: dict containing the current velocity:\n",
    "                    v['dW' + str(l)] = ...\n",
    "                    v['db' + str(l)] = ...\n",
    "    beta: the momentum hyperparameter, scalar\n",
    "    learning_rate: the learning rate, scalar\n",
    "    \n",
    "    Returns:\n",
    "    parameters: dict containing updated params \n",
    "    v: dictionary containing updated velocities\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2 # num of layers\n",
    "    \n",
    "    # momentum update for each parameter\n",
    "    for l in range(1, L + 1):\n",
    "        # compute velocities\n",
    "        v[\"dW\" + str(l)] = beta * v[\"dW\" + str(l)] + (1 - beta) * grads[\"dW\" + str(l)]\n",
    "        v[\"db\" + str(l)] = beta * v[\"db\" + str(l)] + (1 - beta) * grads[\"db\" + str(l)]\n",
    "\n",
    "        # update parameters\n",
    "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * v[\"dW\" + str(l)]\n",
    "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * v[\"db\" + str(l)]\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b4fcc-5f05-44d2-86a2-68466d241f68",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f0efb-edb4-4942-83b9-7d7b34d9e703",
   "metadata": {},
   "source": [
    "Adam (_Adaptive Moment Estimation_) merges momentum and RMSprop.\n",
    "\n",
    "Background:\n",
    "- Momentum uses EWAs of gradients to smooth updates.\n",
    "- RMSprop uses EWAs of squared gradients to scale updates adaptively.\n",
    "\n",
    "$V_{dW}$ is the first moment (the mean) which guides the direction of the updates. \\\n",
    "$S_{dW}$ is the second moment (the uncentered variance) which adjusts the step size for each parameter update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba5f68-1a24-477b-af00-66cda50808e5",
   "metadata": {},
   "source": [
    "Initialize all moment vectors at $t = 0$:\n",
    "- $v_{dW} = 0$\n",
    "- $v_{db} = 0$\n",
    "- $S_{dW} = 0$\n",
    "- $S_{db} = 0$\n",
    "\n",
    "During iteration $t$:\n",
    "1. Compute the gradients $dW$, $db$ on the current mini-batch.\n",
    "2. Momentum update (first moment)\n",
    "\t- $v_{dW} = \\beta_1 \\cdot v_{dW} + (1-\\beta_1) \\cdot dW$\n",
    "\t- $v_{db} = \\beta_1 \\cdot v_{db} + (1-\\beta_1) \\cdot db$\n",
    "3. RMSprop update (second moment)\n",
    "\t- $S_{dW} = \\beta_2 \\cdot S_{dW} + (1-\\beta_2) \\cdot dW^2$\n",
    "\t- $S_{db} = \\beta_2 \\cdot S_{db} + (1-\\beta_2) \\cdot db^2$\n",
    "4. Bias correction due to the bias to $0$ caused by initialization\n",
    "\t- $\\displaystyle \\hat v_{dW} = \\frac{v_{dW}}{1-\\beta_1^t}$\n",
    "\t- $\\displaystyle \\hat v_{db} = \\frac{v_{db}}{1-\\beta_1^t}$\n",
    "\t- $\\displaystyle \\hat S_{dW} = \\frac{S_{dW}}{1-\\beta_2^t}$\n",
    "\t- $\\displaystyle \\hat S_{db} = \\frac{S_{db}}{1-\\beta_2^t}$\n",
    "5. Parameter update\n",
    "\t- $\\displaystyle W := W - \\alpha \\frac{\\hat v_{dW}}{\\sqrt{\\hat S_{dW}} + \\varepsilon}$\n",
    "\t- $\\displaystyle b := b - \\alpha \\frac{\\hat v_{db}}{\\sqrt{\\hat S_{db}} + \\varepsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc06db-8701-44d5-9324-d02ed27fb44e",
   "metadata": {},
   "source": [
    "| Hyperparameter | Symbol | Typical value |\n",
    "|----------------|--------|---------------|\n",
    "| Learning rate | $\\alpha$ | needs to be tuned |\n",
    "| Momentum decay rate (first moment) | $\\beta_1$ | 0.9 |\n",
    "| RMSprop decay rate (second moment) | $\\beta_2$ | 0.999 |\n",
    "| Numerical stability constant | $\\varepsilon$ | $10^{-8}$ |\n",
    "\n",
    "Both 0.9 and 0.999 are values proposed by the authors (Kingma et. al.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10d6db12-deee-4d41-94ba-ef44aa47aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters):    \n",
    "    L = len(parameters) // 2 # num of layers\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(1, L + 1):\n",
    "        v[\"dW\" + str(l)] = np.zeros(parameters[\"W\" + str(l)].shape)\n",
    "        v[\"db\" + str(l)] = np.zeros(parameters[\"b\" + str(l)].shape)\n",
    "        s[\"dW\" + str(l)] = np.zeros(parameters[\"W\" + str(l)].shape)\n",
    "        s[\"db\" + str(l)] = np.zeros(parameters[\"b\" + str(l)].shape)\n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77153c53-e644-46ac-8450-715996693909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    parameters: dict containing params:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads: dict containing grads for each param:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    v: Adam variable, moving ave of the first grad, a dict\n",
    "    s: Adam variable, moving ave of the squared grad, a dict\n",
    "    t: Adam variable, counts the num of steps taken for bias correction\n",
    "    learning_rate: learning rate, scalar\n",
    "    beta1: exponential decay hyperparameter for the first moment estimates\n",
    "    beta2: exponential decay hyperparameter for the second moment estimates\n",
    "    epsilon: hyperparameter to prevent division by zero in the Adam update, a small scalar\n",
    "\n",
    "    Returns:\n",
    "    parameters: dict containing updated params\n",
    "    v: updated Adam variable, moving ave of the first grad, a dict\n",
    "    s: updated Adam variable, moving ave of the squared grad, a dict\n",
    "    v_corrected: dict containing bias-corrected first moment estimates\n",
    "    s_corrected: dict containing bias-corrected second moment estimates\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # num of layers\n",
    "    v_corrected = {} # init first moment estimate\n",
    "    s_corrected = {} # init second moment estimate\n",
    "    \n",
    "    for l in range(1, L + 1):\n",
    "        # moving ave of grads\n",
    "        v[\"dW\" + str(l)] = beta1 * v[\"dW\" + str(l)] + (1 - beta1) * grads[\"dW\" + str(l)]\n",
    "        v[\"db\" + str(l)] = beta1 * v[\"db\" + str(l)] + (1 - beta1) * grads[\"db\" + str(l)]\n",
    "\n",
    "        # bias-corrected first moment estimate\n",
    "        v_corrected[\"dW\" + str(l)] = v[\"dW\" + str(l)] / (1 - beta1 ** t)\n",
    "        v_corrected[\"db\" + str(l)] = v[\"db\" + str(l)] / (1 - beta1 ** t)\n",
    "\n",
    "        # moving ave of the squared grads\n",
    "        s[\"dW\" + str(l)] = beta2 * s[\"dW\" + str(l)] + (1 - beta2) * (grads[\"dW\" + str(l)])**2\n",
    "        s[\"db\" + str(l)] = beta2 * s[\"db\" + str(l)] + (1 - beta2) * (grads[\"db\" + str(l)])**2\n",
    "        \n",
    "        # bias-corrected second raw moment estimate\n",
    "        s_corrected[\"dW\" + str(l)] = s[\"dW\" + str(l)] / (1 - beta2 ** t)\n",
    "        s_corrected[\"db\" + str(l)] = s[\"db\" + str(l)] / (1 - beta2 ** t)\n",
    "        \n",
    "        # update params\n",
    "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * v_corrected[\"dW\" + str(l)] / (np.sqrt(s_corrected[\"dW\" + str(l)]) + epsilon)\n",
    "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * v_corrected[\"db\" + str(l)] / (np.sqrt(s_corrected[\"db\" + str(l)]) + epsilon)\n",
    "\n",
    "    return parameters, v, s, v_corrected, s_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08638592-b811-4403-883e-254dc3e16b66",
   "metadata": {},
   "source": [
    "## Learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e033df36-297d-4b21-a2d2-8a76eccd7543",
   "metadata": {},
   "source": [
    "Learning rate decay can speed up a learning algorithm by slowly reducing learning rate over time.\n",
    "\n",
    "Exponential learning rate decay:\n",
    "$$\\alpha = \\frac{1}{1 + \\text{decay rate} \\times \\text{epoch number}} \\alpha_{0}$$\n",
    "- $\\text{decay factor} < 1$\n",
    "- $\\alpha$ decreases exponentially fast.\n",
    "\n",
    "Inverse learning rate decay:\n",
    "$$\\alpha = \\frac{k \\cdot a_0}{\\sqrt{\\text{epoch num}}}$$\n",
    "- $k$ is a constant.\n",
    "\n",
    "Mini-batch learning rate decay:\n",
    "$$\\alpha = \\frac{k \\cdot a_0}{\\sqrt{t}}$$\n",
    "- $t$ is the mini-batch number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c093446-359f-41ae-985c-65647784f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(learning_rate0, epoch_num, decay_rate):\n",
    "    denominator = 1 + decay_rate * epoch_num\n",
    "    learning_rate = (1 / denominator) * learning_rate0\n",
    "    \n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06e7ec-e6b4-4b27-b120-1d8f6ebd13a7",
   "metadata": {},
   "source": [
    "The new learning rate using exponential weight decay with fixed interval scheduling.\n",
    "\n",
    "$$\\alpha = \\frac{1}{1 + \\text{decay rate} \\times \\lfloor\\frac{\\text{epoch num}}{\\text{time interval}}\\rfloor} \\alpha_{0}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5139478e-1169-49f9-b48d-29dcadf255aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_lr_decay(learning_rate0, epoch_num, decay_rate, time_interval=1000):\n",
    "    denominator = 1 + decay_rate * np.floor(epoch_num/time_interval)\n",
    "    learning_rate = (1 / denominator) * learning_rate0\n",
    "    \n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef249570-6cef-40bd-9840-38dbd69533ae",
   "metadata": {},
   "source": [
    "## Model with different optimization algorithms and learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52996e-c930-454f-b564-4fb86db7a3ca",
   "metadata": {},
   "source": [
    "3-layer neural network model which can be run in different optimizer modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90652ed0-d73b-435a-9330-2c7193f5dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, optimizer, learning_rate=0.0007, \n",
    "          mini_batch_size=64, beta=0.9, beta1=0.9, beta2=0.999,\n",
    "          epsilon=1e-8, num_epochs=5000, print_cost=True, decay=None, decay_rate=1):\n",
    "    \n",
    "    L = len(layers_dims) # num of layers\n",
    "    costs = []                       \n",
    "    t = 0 # counter required for Adam update\n",
    "    m = X.shape[1] # num of train examples\n",
    "    lr_rates = []\n",
    "    learning_rate0 = learning_rate   # original learning rate\n",
    "    \n",
    "    # init params\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    # init optimizer\n",
    "    if optimizer == \"gd\":\n",
    "        pass\n",
    "    elif optimizer == \"momentum\":\n",
    "        v = initialize_velocity(parameters)\n",
    "    elif optimizer == \"adam\":\n",
    "        v, s = initialize_adam(parameters)\n",
    "    \n",
    "    # optimization loop\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        # create random minibatches\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size)\n",
    "        cost_total = 0\n",
    "        \n",
    "        for minibatch_X, minibatch_Y in minibatches:\n",
    "            a3, caches = forward_propagation(minibatch_X, parameters) # forward prop\n",
    "            cost_total += compute_cost(a3, minibatch_Y) # compute cost and add to total\n",
    "            grads = backward_propagation(minibatch_X, minibatch_Y, caches) # back prop\n",
    "\n",
    "            # update params\n",
    "            if optimizer == \"gd\":\n",
    "                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "            elif optimizer == \"momentum\":\n",
    "                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n",
    "            elif optimizer == \"adam\":\n",
    "                t += 1  # Adam counter\n",
    "                parameters, v, s, _, _ = update_parameters_with_adam(\n",
    "                    parameters, grads, v, s, t, learning_rate, beta1, beta2, epsilon)\n",
    "\n",
    "        cost_avg = cost_total / m\n",
    "\n",
    "        # appy learning rate decay\n",
    "        if decay:\n",
    "            learning_rate = decay(learning_rate0, i, decay_rate)\n",
    "\n",
    "        # print cost every 1000 epochs\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(f\"Cost after epoch {i}: {cost_avg:.6f}\")\n",
    "            if decay:\n",
    "                print(f\"Learning rate after epoch {i}: {learning_rate:.6f}\")\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost_avg)\n",
    "                \n",
    "    # plot cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(f\"Learning rate = {learning_rate}\")\n",
    "    plt.show()\n",
    "\n",
    "    return parameters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLS",
   "language": "python",
   "name": "dls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
